{% extends "master.html" %}

{% block title %} Morality {% endblock %}

{% block head %}

<link rel="stylesheet" href="../css/desc.css">

{% endblock %}

{% block content %}

<div class="information">

    <h1 class="informationHeader">Robots morality (Machine Ethics)</h1>

    <div class="informationParagraphs">
        <p>

            Robots, intended as autonomous electro-mechanical machines, have been theorized and studied for over a century.
            Today, thanks to the advancements in technology, robots are becoming a reality.
            We have the hardware, but we are still lacking with the software.
            Unmanned aerial vehicles (drones) used by the military still require a human operator to make ethical decisions.
        </p>
        <p>
            To address these concerns, new fields of research have been formed:
        </p>
        <p>
            <img src="../content/13.png" style="width:323px;height:256px;">
        </p>
        <p>
            <b>Roboethics</b> refer to the morality of how humans design, construct, use and treat robots and other artificially intelligent beings.
            The first symposium on this matter was held in 2004.</br>
            <b>Machine Ethics</b> refer to the moral behavior of artificially intelligent beings.
        </p>
        <p>
            Most researchers agree on the fact that robots cannot have a conscience.
            They main question of today is: can robots be programmed to make ethical decisions? Are ethics even computable?
            Absolute rules are definitely computable, but we humans never deal in absolutes when making a decision.
            As our legal system proves, there are a lot of grey areas, exceptions and contradictions that play a role when making a decision in a court of law.
        </p>
        <p>
            <img src="../content/12.png" style="width:392px;height:269px;">
        </p>
        <p>
            In 2011, the Engineering and Physical Sciences Research Council (EPRSC) and the Arts and Humanities Research Council (AHRC) of Great Britain
            jointly published a set of five ethical principles for designers, builders and users of robots:
            <ol>
            <li>Robots are multi-use tools. Robots should not be designed solely or primarily to kill or harm humans, except in the interests of national security.</li>
            <li>Humans, not Robots, are responsible agents. Robots should be designed and operated as far as practicable to comply with existing laws, fundamental rights and freedoms, including privacy.</li>
            <li>Robots are products. They should be designed using processes which assure their safety and security.</li>
            <li>Robots are manufactured artefacts. They should not be designed in a deceptive way to exploit vulnerable users; instead their machine nature should be transparent.</li>
            <li>The person with legal responsibility for a robot should be attributed.</li>
            </ol>
        </p>
        <p>
            The research in Robot morality is considered a top priority by prominent figures of the techno-logical world,
            fearing the creation of the singularity, a sentient being capable of recursive self-improving.
            Some of them consider the AI more dangerous than nuclear weapons.
        </p>
        <p>
            <img src="../content/16.png" style="width:410px;height:292px;">
        </p>

    </div>

</div>


{% endblock %}
