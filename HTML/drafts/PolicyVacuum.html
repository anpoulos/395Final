<!DOCTYPE html>
<html lang = "en">
<head></head>
<body>
<h1> <b> <ins>Policy Vacuum in Military AI</ins></b></h1>
<p>
    As we know, a policy vacuum happens when we have no rules or laws pertaining to a new phenomenon that has never been<br>
    seen before. This is very apparent in the world of military AI. The questions are endless. Who's responsible? <br>
    Can we control them? What do we do if we can't control them? Nobody knows what we should do about it just yet, <br>
    however many forces in the science field argue that we should halt our research in AI all together. It's just like<br>
    all of those post-apocalyptic movies we've watched, Robots become too smart and overpower the human race, causing <br>
    our eradication. That's what these people say are to come, but what have we done to prepare us for it? The United States<br>
    Department of Defense has made a document that states how they will be handling the use of Robotics and AI in the <br>
    military. "Autonomous and semi-autonomous weapon systems shall be designed to allow commanders and operators to <br>
    exercise appropriate levels of human judgement over the use of force." Is just one quote from this paper, however it<br>
    begs the question, what if we can't stop them? What if they refuse to listen to their commanders? And once we've <br>
    made it this far, can we ever go back?
</p>
</body>
</html>