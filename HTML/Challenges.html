{% extends "master.html" %}

{% block title %} Challenges {% endblock %}

{% block head %}

<link rel="stylesheet" href="../css/desc.css">

{% endblock %}

{% block content %}

<div class="information">

    <h1 class="informationHeader">Challenges – Autonomous Ethics</h1>

    <div class="informationParagraphs">
        <p>
            It should be clear, and quite trivial, that the formulation of ethics pertaining to artificial intelligence proposes a number of
            challenges – both known and unknown.  So, starting with what we know; the challenges faced can be broken down into a few categories.
        </p><br>
        <p align="center" style="font-weight: bold">
            1.	Legal Challenges – The Responsibility Dilemma
        </p>
        <p>
            The introduction of militarized AI produces numerous legal dilemmas that must be addressed.
            Many of these issues are derivative of a single problem which we’ll dub the Responsibility Dilemma.
            The Responsibility Dilemma entails how we should deal with negative consequences that result from an autonomous decision or action and,
            most importantly, who is responsible for said consequences.  This might involve any sort of physical, emotional, or monetary harm as
            a direct result of an entirely autonomous decision.
            <div style="float: right"><img src="../content/challenges/legalai.png"></div>
        </p>
        <p>
            The problem boils down to one overarching question.  How do we categorize artificial intelligence?<br><br>
            If autonomous robotics do in fact become advanced enough to mimic human intelligence and conscious thought, should they be held
            responsible for their own actions? If so, do we then go so far as to attribute humanoid autonomous robots the same innate rights as
            any other human being? Or, is artificial intelligence to be considered a product or invention that would relay any responsibility back to the creator?
            I believe the key to answering all these questions lies in the depth of autonomy that is being dealt with.
            Even today, military AI exists and is being implemented in manners such as bomb-defusing or drone strikes,
            but these are nowhere near human intelligence levels. There is still direct human influence controlling crucial functions such as the ability of a drone to actually launch an attack.
            Obviously, responsibility for AI of this nature would fall to the controller or military (commanding officer) that issued its use.
            The true problems we face lie in the future of autonomy which is fast approaching.
        </p><br>
        <p align="center" style="font-weight: bold">
            2.	Militarization Factor
        </p>
        <p>
            Dealing with the legality of autonomous robotics is already an enormous void of unknown variables and technicalities.
            Yet, the issues become even more complex when we introduce the Militarization Factor.
            The Responsibility Dilemma again comes into play when examining the issues of autonomous military applications but, this time,
            the stakes are much higher.</p>

        <p>
            For example:<br>
            “Oops, an error caused me to spill hot coffee on a stranger.  I guess my owner will have to pay for any medical bills”
            <b>- Civilian Robot</b><br>
            “Oops, an error caused me to spill my grenades, killing my entire squad.  I guess the military is responsible?”
            <b>- Military Robot</b><br><br>
            Clearly, responsibility is much more important in the second hypothetical situation.  Yet responsibility is only one of the major issues
            involved with militarized AI.  With fully autonomous military robotics we delve into deeper ethical issues such as attack initiatives,
            command refusal, and even societal or international effects spawned from the implementation of such technologies.
        </p><br>
        <p align="center" style="font-weight: bold">
            3.	Technical Challenges
        </p>
        <p>
            Many of the technical challenges faced by autonomous robotics involve the implementation of an ethical framework.
            Even a simple framework could have conflicting interests for various situations; again, even more so for military incurrence.
            Such conflicts could produce unpredictable, erratic behavior:
            <div style="float: left"><img src="../content/challenges/drone.png"></div>
        </p>

         <p style="font-size: small">
            “Asimov’s Laws appear to be as simple as programmable rules can be for autonomous robots, yet they yielded surprising, unintended consequences
            in his stories [e.g., Asimov, 1950].”
         </p>
         <p>
            Even the most professional programmer can let an error or two slip by without notice.  The problem is that, especially with such an advanced
            system as AI, there is no reasonable way to test every possible situation.  Errors will inevitably fall through the cracks and as such,
            we must be ethically prepared to address the unforeseen consequences.  Other technical challenges include unauthorized override (hacking),
            robotic revolution (see Terminator), and even internal coordination (between other robots).
        </p><br>
        <p align="center" style="font-weight: bold">
            4.	 Cultural & Societal Challenges
        </p>
        <p>
            As with any new technology, there will be many unforeseen effects on society and culture as a whole if fully autonomous robots are introduced
            into the world.
            How will robotic immersion affect daily life? How will it affect war – does it make war a simpler option if combatant casualties are reduced?
            Do robots have the right to self-defense?  Is civil security a concern if civilians are able to own and operate (issue commands to)
            their own autonomous robots?  These questions and many more will be addressed in the discussion of the ethical challenges created by
            the introduction of military artificial intelligence.
       </p>

    </div>

</div>


{% endblock %}
